{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/20/16-5/1/16: Reviewed literature and settled on the MLP2LN for the Iris and Mushroom datasets. Proposal written, submitted, accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/5/16: Reviewed timeline and set sub-deadlines.\n",
    "6th sunday: write algorithm\n",
    "7th week: make model!\n",
    "8th Wednesday 5/18: Running model\n",
    "9th Monday 5/23: Have running model on data, data analysis, outline of presentation/paper\n",
    "9th Friday: presentation\n",
    "10th wednesday: paper due\n",
    "\n",
    "Action Steps:\n",
    "1. Review papers, attempt to glean basic idea / algorithm.\n",
    "2. Put together algorithm.\n",
    "3. Write basic class structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/8/16: Reviewed papers on MLP2LN algorithms to start writing pseudocode. \n",
    "Important equations:\n",
    "\n",
    "For labeling features (eq 2): IF $x_i \\in  X_{ij}$ THEN $(s_k=label(x_k) = T)$\n",
    "\n",
    "Weight pruning (eq 4): $W_{ij} \\leftarrow W_{ij} + \\lambda W_{ij} (W_{ij}^2 -1) (3W_{ij}^2 - 1)$\n",
    "\n",
    "Weight training (eq 9 in p1, 10 in p2): \n",
    "$\\frac{1}{2}\\Sigma_p\\Sigma_k (Y_k^p - A_W(X^p)_k)^2 + \\frac{\\lambda_1}{2} \\Sigma_{i>j} W^2_{ij} + \\frac{\\lambda_2}{2}\\Sigma_{i>j}W^2_{ij} (W_{ij} - 1)^2 (W_{ij} + 1)^2$\n",
    "\n",
    "\n",
    "Algorithm:\n",
    "1. Create one hidden neuron\n",
    "2. Train that neuron on data using backpropogation with regularization. $\\lambda_1 = 10^{-5}$ and $\\lambda_2 = 0$\n",
    "3. Train as long as the error decreases. Then increase $\\lambda_1$ by a factor of $10$ until a sharp increase of the error. If after increasing $\\lambda_1$ there's an increase of a factor of 5 in the error, stop. Decrease $\\lambda_1$ returns to previous state. Remove weights smaller than $|.1|$. Set $\\lambda_2 = \\lambda_1$ and $\\lambda_1 = 0$. Train slowly, increasing the slopes in $\\lambda_2$ until weights reach $0 \\pm 0.05$ or $\\pm 1 \\pm 0.05$. Set very large T (about one thousand) and set integer weights to $0 , \\pm 1$. \n",
    "4. Analyse the weights and the thresholds obtained \n",
    "5. Freeze the weights of existing neurons. \n",
    "6. Add the next neurone. Be sure to connect it to the output neuron.\n",
    "7. Repeat the procdedure until all data is correctly classified or the number of rules obtained grows sharply.\n",
    "\n",
    "\n",
    "Questions:\n",
    "1. What's the unit slope / sigmoidal function (step 2, step 3a)?\n",
    "2. How do they get the rules out of the network?\n",
    "3. Why doesn't Fig 1 match the table for the Iris problem?\n",
    "4. What are the deltas?\n",
    "\n",
    "\n",
    "Next Steps:\n",
    "1. Figure out how to get the rules from the network\n",
    "2. How do we get the threshold $\\theta$ and the $\\delta$\n",
    "3. Go ask Anna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
